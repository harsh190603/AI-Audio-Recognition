{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping (Classname -> Index):\n",
      "{'breath': 0, 'cough': 1, 'crying': 2, 'laugh': 3, 'screaming': 4, 'sneeze': 5, 'yawn': 6}\n",
      "\n",
      "Starting 3-Fold Cross-Validation...\n",
      "\n",
      "--- Fold 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1: 100%|██████████| 524/524 [02:16<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1 Loss: 1.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2: 100%|██████████| 524/524 [01:54<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2 Loss: 1.6356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 3: 100%|██████████| 524/524 [01:56<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 3 Loss: 1.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 4: 100%|██████████| 524/524 [02:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 4 Loss: 1.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 5: 100%|██████████| 524/524 [02:03<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 5 Loss: 1.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 6: 100%|██████████| 524/524 [02:06<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 6 Loss: 1.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 7: 100%|██████████| 524/524 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 7 Loss: 1.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 8: 100%|██████████| 524/524 [02:09<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 8 Loss: 1.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 9: 100%|██████████| 524/524 [02:10<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 9 Loss: 1.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 10: 100%|██████████| 524/524 [02:12<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 10 Loss: 1.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harsh\\Desktop\\Audio Recognition Project\\venv1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - F1: 0.1202, Precision: 0.0768, Recall: 0.2771\n",
      "\n",
      "--- Fold 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 1: 100%|██████████| 525/525 [02:20<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 1 Loss: 1.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 2: 100%|██████████| 525/525 [02:22<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 2 Loss: 1.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 3: 100%|██████████| 525/525 [02:23<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 3 Loss: 1.6281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 4: 100%|██████████| 525/525 [02:16<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 4 Loss: 1.6140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 5: 100%|██████████| 525/525 [02:13<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 5 Loss: 1.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 6: 100%|██████████| 525/525 [02:13<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 6 Loss: 1.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 7: 100%|██████████| 525/525 [02:12<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 7 Loss: 1.6014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 8: 100%|██████████| 525/525 [02:11<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 8 Loss: 1.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 9: 100%|██████████| 525/525 [02:11<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 9 Loss: 1.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 10: 100%|██████████| 525/525 [02:11<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 10 Loss: 1.6164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harsh\\Desktop\\Audio Recognition Project\\venv1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - F1: 0.3029, Precision: 0.2672, Recall: 0.4208\n",
      "\n",
      "--- Fold 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 1: 100%|██████████| 525/525 [02:12<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 1 Loss: 1.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 2: 100%|██████████| 525/525 [02:11<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 2 Loss: 1.6415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 3: 100%|██████████| 525/525 [02:11<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 3 Loss: 1.6284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 4: 100%|██████████| 525/525 [02:11<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 4 Loss: 1.6165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 5: 100%|██████████| 525/525 [02:09<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 5 Loss: 1.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 6: 100%|██████████| 525/525 [02:11<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 6 Loss: 1.6172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 7: 100%|██████████| 525/525 [02:10<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 7 Loss: 1.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 8: 100%|██████████| 525/525 [02:10<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 8 Loss: 1.6247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 9: 100%|██████████| 525/525 [02:10<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 9 Loss: 1.6143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 10: 100%|██████████| 525/525 [02:10<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 10 Loss: 1.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harsh\\Desktop\\Audio Recognition Project\\venv1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - F1: 0.2537, Precision: 0.1998, Recall: 0.3626\n",
      "\n",
      "--- Average 3-Fold Cross-Validation Results ---\n",
      "F1 Score: 0.2256\n",
      "Precision: 0.1812\n",
      "Recall: 0.3535\n",
      "\n",
      "Training final model on full training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 1/10: 100%|██████████| 787/787 [03:15<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 2/10: 100%|██████████| 787/787 [03:15<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 1.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 3/10: 100%|██████████| 787/787 [03:15<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 1.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 4/10: 100%|██████████| 787/787 [03:14<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 1.7081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 5/10: 100%|██████████| 787/787 [03:15<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 1.7056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 6/10: 100%|██████████| 787/787 [03:15<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 1.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 7/10: 100%|██████████| 787/787 [03:14<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 1.7017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 8/10: 100%|██████████| 787/787 [03:14<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 1.7018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 9/10: 100%|██████████| 787/787 [03:14<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 1.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 10/10: 100%|██████████| 787/787 [03:14<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 1.7041\n",
      "Final training complete. Model saved as 'trained_model_from_scratch.pth'.\n",
      "Test Accuracy: 43.31%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------\n",
    "# 1. Add the PANNs model directory to the system path\n",
    "# -------------------------\n",
    "pytorch_path = r\"C:\\\\Users\\\\Harsh\\\\Desktop\\\\Audio Recognition Project\\\\audioset_tagging_cnn-master\\\\pytorch\"\n",
    "sys.path.insert(0, pytorch_path)\n",
    "\n",
    "# Import model (we use Cnn14 in this example)\n",
    "from models import Cnn14\n",
    "\n",
    "# -------------------------\n",
    "# 2. Configuration and Paths\n",
    "# -------------------------\n",
    "DATASET_PATH = r\"C:\\\\Users\\\\Harsh\\\\Desktop\\\\Audio Recognition Project\\\\dataset\"\n",
    "\n",
    "TRAIN_METADATA_CSV = os.path.join(DATASET_PATH, \"metadata of train set.csv\")\n",
    "TEST_METADATA_CSV  = os.path.join(DATASET_PATH, \"metadata of test set.csv\")\n",
    "\n",
    "TRAIN_AUDIO_DIR = os.path.join(DATASET_PATH, \"train\")\n",
    "TEST_AUDIO_DIR  = os.path.join(DATASET_PATH, \"test\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Audio Processing Parameters\n",
    "# -------------------------\n",
    "SAMPLE_RATE = 32000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 320\n",
    "N_MELS = 64\n",
    "FMIN = 50\n",
    "FMAX = 14000\n",
    "\n",
    "# (No need for a mel_transform here because the model internally computes spectrograms.)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Prepare Metadata and Create Class Mapping\n",
    "# -------------------------\n",
    "train_meta = pd.read_csv(TRAIN_METADATA_CSV)\n",
    "train_meta.columns = train_meta.columns.str.strip()\n",
    "\n",
    "# We use the \"Classname\" column as the label.\n",
    "classes = sorted(train_meta[\"Classname\"].unique())\n",
    "class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "num_classes = len(classes)\n",
    "print(\"Class mapping (Classname -> Index):\")\n",
    "print(class_to_idx)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Define the Custom Dataset (Return Raw Waveform)\n",
    "# -------------------------\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, metadata_csv, audio_dir, class_to_idx, transform=None):\n",
    "        self.metadata = pd.read_csv(metadata_csv)\n",
    "        self.metadata.columns = self.metadata.columns.str.strip()\n",
    "        self.audio_dir = audio_dir\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        filename = row[\"Filename\"]\n",
    "        label = self.class_to_idx[row[\"Classname\"]]\n",
    "        file_path = os.path.join(self.audio_dir, filename)\n",
    "        \n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "        # If stereo, take the first channel.\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform[0:1, :]\n",
    "        # Resample if needed.\n",
    "        if sr != SAMPLE_RATE:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "            waveform = resampler(waveform)\n",
    "        # Squeeze to make the waveform 1D.\n",
    "        waveform = waveform.squeeze(0)  # shape: [data_length]\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "# Create dataset instances.\n",
    "train_dataset = AudioDataset(TRAIN_METADATA_CSV, TRAIN_AUDIO_DIR, class_to_idx, transform=None)\n",
    "test_dataset = AudioDataset(TEST_METADATA_CSV, TEST_AUDIO_DIR, class_to_idx, transform=None)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Custom Collate Function for Raw Waveforms\n",
    "# -------------------------\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads raw 1D waveforms in the batch along the time dimension\n",
    "    so that all waveforms have the same length.\n",
    "    \"\"\"\n",
    "    waveforms, labels = zip(*batch)\n",
    "    max_length = max(waveform.shape[0] for waveform in waveforms)\n",
    "    padded_waveforms = []\n",
    "    for waveform in waveforms:\n",
    "        pad_length = max_length - waveform.shape[0]\n",
    "        padded_waveform = F.pad(waveform, (0, pad_length))\n",
    "        padded_waveforms.append(padded_waveform)\n",
    "    stacked_waveforms = torch.stack(padded_waveforms, dim=0)  # shape: [batch_size, max_length]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return stacked_waveforms, labels\n",
    "\n",
    "# Create DataLoaders with the custom collate function.\n",
    "train_loader_full = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# -------------------------\n",
    "# 7. Define Model Parameters and Initialize Model\n",
    "# -------------------------\n",
    "model_params = {\n",
    "    \"sample_rate\": SAMPLE_RATE,\n",
    "    \"window_size\": N_FFT,\n",
    "    \"hop_size\": HOP_LENGTH,\n",
    "    \"mel_bins\": N_MELS,\n",
    "    \"fmin\": FMIN,\n",
    "    \"fmax\": FMAX,\n",
    "    \"classes_num\": num_classes  # For example, 7 if you have 7 classes.\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# 8. 3-Fold Cross-Validation on Training Set\n",
    "# -------------------------\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "fold_f1 = []\n",
    "fold_precision = []\n",
    "fold_recall = []\n",
    "\n",
    "print(\"\\nStarting 3-Fold Cross-Validation...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"\\n--- Fold {fold+1} ---\")\n",
    "    \n",
    "    # Create subsets for training and validation for this fold.\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    # Initialize a new model for this fold.\n",
    "    model_fold = Cnn14(**model_params)\n",
    "    model_fold.to(DEVICE)\n",
    "    optimizer_fold = optim.Adam(model_fold.parameters(), lr=LEARNING_RATE)\n",
    "    criterion_fold = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train for the specified number of epochs.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model_fold.train()\n",
    "        running_loss = 0.0\n",
    "        for waveforms, labels in tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}\"):\n",
    "            waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer_fold.zero_grad()\n",
    "            outputs = model_fold(waveforms)\n",
    "            logits = outputs[\"clipwise_output\"]  # Extract classification logits.\n",
    "            loss = criterion_fold(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer_fold.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Fold {fold+1} Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    # Evaluate on the validation set for this fold.\n",
    "    model_fold.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels in val_loader:\n",
    "            waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model_fold(waveforms)\n",
    "            logits = outputs[\"clipwise_output\"]\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    fold_f1.append(f1_score(all_labels, all_preds, average=\"weighted\"))\n",
    "    fold_precision.append(precision_score(all_labels, all_preds, average=\"weighted\"))\n",
    "    fold_recall.append(recall_score(all_labels, all_preds, average=\"weighted\"))\n",
    "    print(f\"Fold {fold+1} - F1: {fold_f1[-1]:.4f}, Precision: {fold_precision[-1]:.4f}, Recall: {fold_recall[-1]:.4f}\")\n",
    "\n",
    "# Print average metrics across folds.\n",
    "avg_f1 = np.mean(fold_f1)\n",
    "avg_precision = np.mean(fold_precision)\n",
    "avg_recall = np.mean(fold_recall)\n",
    "print(\"\\n--- Average 3-Fold Cross-Validation Results ---\")\n",
    "print(f\"F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 9. Optionally, Train on Full Training Set and Evaluate on Test Set\n",
    "# -------------------------\n",
    "# (This part is separate from cross-validation; you can choose to train a final model on all training data.)\n",
    "model_final = Cnn14(**model_params)\n",
    "model_final.to(DEVICE)\n",
    "optimizer_final = optim.Adam(model_final.parameters(), lr=LEARNING_RATE)\n",
    "criterion_final = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\nTraining final model on full training set...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model_final.train()\n",
    "    total_loss = 0.0\n",
    "    for waveforms, labels in tqdm(train_loader_full, desc=f\"Final Model Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer_final.zero_grad()\n",
    "        outputs = model_final(waveforms)\n",
    "        logits = outputs[\"clipwise_output\"]\n",
    "        loss = criterion_final(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer_final.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Training Loss: {total_loss/len(train_loader_full):.4f}\")\n",
    "\n",
    "torch.save(model_final.state_dict(), \"trained_model_from_scratch.pth\")\n",
    "print(\"Final training complete. Model saved as 'trained_model_from_scratch.pth'.\")\n",
    "\n",
    "# Evaluate on the test set.\n",
    "model_final.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for waveforms, labels in test_loader:\n",
    "        waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model_final(waveforms)\n",
    "        logits = outputs[\"clipwise_output\"]\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
