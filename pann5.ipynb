{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a Pretrained PANN Model for Audio Classification\n",
    "\n",
    "This notebook fine-tunes a pretrained **CNN14** model—a variant of **PANNs** (Pretrained Audio Neural Networks)—on a custom 7-class audio dataset. Our dataset consists of the following classes: *breath, cough, crying, laugh, screaming, sneeze,* and *yawn*.  \n",
    "> **Note:** The original \"metadata for test set.csv\" mistakenly labeled all files for the \"yawn\" class as **\"yawm\"** (an anomaly), which was corrected prior to training.\n",
    "\n",
    "## About PANNs\n",
    "\n",
    "**PANNs** stands for **Pretrained Audio Neural Networks**. These models were introduced in the paper:\n",
    "\n",
    "> **PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition**  \n",
    "> *Qiuqiang Kong, Yin Cao, Turab Iqbal, Yuxuan Wang, Wenwu Wang, and Mark D. Plumbley, IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020.*\n",
    "\n",
    "### Architecture Overview – CNN14\n",
    "\n",
    "- **Input Processing:**  \n",
    "  The CNN14 model takes raw audio waveforms (resampled to 32 kHz) as input and internally computes time–frequency representations using the Short-Time Fourier Transform (STFT) and mel spectrogram extraction.\n",
    "\n",
    "- **Convolutional Blocks:**  \n",
    "  A series of convolutional layers extract both local and global audio features, capturing diverse acoustic patterns learned from large-scale data.\n",
    "\n",
    "- **Final Layers:**  \n",
    "  Originally, the model’s final fully connected layer was trained on AudioSet (527 classes). For our task, the final classification layer is reinitialized for our 7-class problem.\n",
    "\n",
    "The model’s code is taken from GitHub ([https://github.com/qiuqiangkong/audioset_tagging_cnn.git](https://github.com/qiuqiangkong/audioset_tagging_cnn.git)), and the pretrained weights (e.g., CNN14 achieving mAP = 0.431 on AudioSet) were downloaded from Zenodo ([https://zenodo.org/record/3987831](https://zenodo.org/record/3987831)).\n",
    "\n",
    "## Training Details\n",
    "\n",
    "- **Pretrained Weights:**  \n",
    "  I initially attempted to train the model from scratch (without using pretrained weights), but the performance was very poor—around **40% accuracy**. Therefore, I chose to fine-tune a model initialized with pretrained weights (excluding the final classification layer), which dramatically improved performance.\n",
    "\n",
    "- **Training Setup:**  \n",
    "  - **Number of Epochs:** 20  \n",
    "  - **Learning Rate:** 1e-4  \n",
    "  - **Optimizer:** Adam  \n",
    "  - **Batch Size:** 8  \n",
    "\n",
    "## Results\n",
    "\n",
    "- **3-Fold Cross-Validation (on Training Data):**  \n",
    "  - **Average F1 Score:** ~95.4%  \n",
    "  - **Average Precision:** ~95.5%  \n",
    "  - **Average Recall:** ~95.4%\n",
    "\n",
    "- **Final Model Evaluation on Test Set:**  \n",
    "  - **Test Accuracy:** ~90.5%\n",
    "\n",
    "These results demonstrate that fine-tuning the pretrained CNN14 model on our dataset yields excellent performance, with robust cross-validation metrics and a high test accuracy.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping (Classname -> Index):\n",
      "{'breath': 0, 'cough': 1, 'crying': 2, 'laugh': 3, 'screaming': 4, 'sneeze': 5, 'yawn': 6}\n",
      "Loaded pretrained weights (excluding final layer) successfully.\n",
      "\n",
      "Starting 3-Fold Cross-Validation...\n",
      "\n",
      "--- Fold 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1: 100%|██████████| 524/524 [01:56<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1 Loss: 1.4765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2: 100%|██████████| 524/524 [02:08<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2 Loss: 1.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 3: 100%|██████████| 524/524 [02:17<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 3 Loss: 1.2947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 4: 100%|██████████| 524/524 [02:25<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 4 Loss: 1.2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 5: 100%|██████████| 524/524 [02:27<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 5 Loss: 1.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 6: 100%|██████████| 524/524 [02:31<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 6 Loss: 1.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 7: 100%|██████████| 524/524 [02:33<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 7 Loss: 1.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 8: 100%|██████████| 524/524 [02:06<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 8 Loss: 1.2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 9: 100%|██████████| 524/524 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 9 Loss: 1.2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 10: 100%|██████████| 524/524 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 10 Loss: 1.2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 11: 100%|██████████| 524/524 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 11 Loss: 1.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 12: 100%|██████████| 524/524 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 12 Loss: 1.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 13: 100%|██████████| 524/524 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 13 Loss: 1.2135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 14: 100%|██████████| 524/524 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 14 Loss: 1.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 15: 100%|██████████| 524/524 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 15 Loss: 1.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 16: 100%|██████████| 524/524 [02:06<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 16 Loss: 1.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 17: 100%|██████████| 524/524 [02:06<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 17 Loss: 1.2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 18: 100%|██████████| 524/524 [02:06<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 18 Loss: 1.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 19: 100%|██████████| 524/524 [02:06<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 19 Loss: 1.1962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 20: 100%|██████████| 524/524 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 20 Loss: 1.1970\n",
      "Fold 1 - F1: 0.9531, Precision: 0.9538, Recall: 0.9528\n",
      "\n",
      "--- Fold 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 1: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 1 Loss: 1.4703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 2: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 2 Loss: 1.3254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 3: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 3 Loss: 1.2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 4: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 4 Loss: 1.2720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 5: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 5 Loss: 1.2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 6: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 6 Loss: 1.2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 7: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 7 Loss: 1.2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 8: 100%|██████████| 525/525 [02:08<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 8 Loss: 1.2390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 9: 100%|██████████| 525/525 [02:07<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 9 Loss: 1.2290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 10: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 10 Loss: 1.2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 11: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 11 Loss: 1.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 12: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 12 Loss: 1.2147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 13: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 13 Loss: 1.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 14: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 14 Loss: 1.2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 15: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 15 Loss: 1.2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 16: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 16 Loss: 1.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 17: 100%|██████████| 525/525 [02:08<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 17 Loss: 1.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 18: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 18 Loss: 1.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 19: 100%|██████████| 525/525 [02:08<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 19 Loss: 1.2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 20: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 20 Loss: 1.2009\n",
      "Fold 2 - F1: 0.9563, Precision: 0.9571, Recall: 0.9566\n",
      "\n",
      "--- Fold 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 1: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 1 Loss: 1.4807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 2: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 2 Loss: 1.3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 3: 100%|██████████| 525/525 [02:08<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 3 Loss: 1.2941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 4: 100%|██████████| 525/525 [02:08<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 4 Loss: 1.2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 5: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 5 Loss: 1.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 6: 100%|██████████| 525/525 [02:08<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 6 Loss: 1.2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 7: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 7 Loss: 1.2390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 8: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 8 Loss: 1.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 9: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 9 Loss: 1.2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 10: 100%|██████████| 525/525 [02:08<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 10 Loss: 1.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 11: 100%|██████████| 525/525 [02:08<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 11 Loss: 1.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 12: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 12 Loss: 1.2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 13: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 13 Loss: 1.2147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 14: 100%|██████████| 525/525 [02:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 14 Loss: 1.2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 15: 100%|██████████| 525/525 [02:07<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 15 Loss: 1.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 16: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 16 Loss: 1.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 17: 100%|██████████| 525/525 [02:07<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 17 Loss: 1.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 18: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 18 Loss: 1.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 19: 100%|██████████| 525/525 [02:07<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 19 Loss: 1.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 20: 100%|██████████| 525/525 [02:08<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 20 Loss: 1.1982\n",
      "Fold 3 - F1: 0.9525, Precision: 0.9526, Recall: 0.9528\n",
      "\n",
      "--- Average 3-Fold Cross-Validation Results ---\n",
      "F1 Score: 0.9539\n",
      "Precision: 0.9545\n",
      "Recall: 0.9540\n",
      "\n",
      "Training final model on full training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 1/20: 100%|██████████| 787/787 [03:12<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.4278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 2/20: 100%|██████████| 787/787 [03:11<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 1.3038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 3/20: 100%|██████████| 787/787 [03:11<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 1.2720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 4/20: 100%|██████████| 787/787 [03:11<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 1.2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 5/20: 100%|██████████| 787/787 [03:12<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 1.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 6/20: 100%|██████████| 787/787 [03:11<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 1.2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 7/20: 100%|██████████| 787/787 [03:11<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 1.2268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 8/20: 100%|██████████| 787/787 [03:12<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 1.2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 9/20: 100%|██████████| 787/787 [03:11<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 1.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 10/20: 100%|██████████| 787/787 [03:11<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 1.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 11/20: 100%|██████████| 787/787 [03:12<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training Loss: 1.2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 12/20: 100%|██████████| 787/787 [04:13<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training Loss: 1.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 13/20: 100%|██████████| 787/787 [04:59<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training Loss: 1.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 14/20: 100%|██████████| 787/787 [05:12<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training Loss: 1.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 15/20: 100%|██████████| 787/787 [05:01<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training Loss: 1.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 16/20: 100%|██████████| 787/787 [05:01<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training Loss: 1.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 17/20: 100%|██████████| 787/787 [04:59<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training Loss: 1.1971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 18/20: 100%|██████████| 787/787 [05:00<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training Loss: 1.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 19/20: 100%|██████████| 787/787 [04:58<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training Loss: 1.1940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Model Epoch 20/20: 100%|██████████| 787/787 [04:56<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training Loss: 1.1943\n",
      "Final training complete. Model saved as 'trained_model_final.pth'.\n",
      "Test Accuracy: 90.48%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Add the PANNs model directory to the system path\n",
    "# ------------------------------------------------\n",
    "\n",
    "pytorch_path = r\"C:\\\\Users\\\\Harsh\\\\Desktop\\\\Audio Recognition Project\\\\audioset_tagging_cnn-master\\\\pytorch\"\n",
    "sys.path.insert(0, pytorch_path)\n",
    "\n",
    "# Import the CNN14 model from the repository.\n",
    "from models import Cnn14\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Configuration and Paths\n",
    "# ------------------------------------------------\n",
    "DATASET_PATH = r\"C:\\\\Users\\\\Harsh\\\\Desktop\\\\Audio Recognition Project\\\\dataset\"\n",
    "PRETRAINED_MODEL_PATH = r\"C:\\\\Users\\\\Harsh\\\\Desktop\\\\Audio Recognition Project\\\\pretrained_models\\\\PANN\\\\Cnn14_mAP=0.431.pth\"\n",
    "\n",
    "TRAIN_METADATA_CSV = os.path.join(DATASET_PATH, \"metadata of train set.csv\")\n",
    "TEST_METADATA_CSV  = os.path.join(DATASET_PATH, \"metadata of test set.csv\")\n",
    "\n",
    "TRAIN_AUDIO_DIR = os.path.join(DATASET_PATH, \"train\")\n",
    "TEST_AUDIO_DIR  = os.path.join(DATASET_PATH, \"test\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Audio Processing Parameters\n",
    "# ------------------------------------------------\n",
    "SAMPLE_RATE = 32000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 320\n",
    "N_MELS = 64\n",
    "FMIN = 50\n",
    "FMAX = 14000\n",
    "\n",
    "# (The model computes its own spectrograms internally.)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Prepare Metadata and Create Class Mapping\n",
    "# ------------------------------------------------\n",
    "train_meta = pd.read_csv(TRAIN_METADATA_CSV)\n",
    "train_meta.columns = train_meta.columns.str.strip()\n",
    "\n",
    "# Use the \"Classname\" column as the label.\n",
    "classes = sorted(train_meta[\"Classname\"].unique())\n",
    "class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "num_classes = len(classes)\n",
    "print(\"Class mapping (Classname -> Index):\")\n",
    "print(class_to_idx)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5. Define the Custom Dataset (Return Raw Waveform)\n",
    "# ------------------------------------------------\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, metadata_csv, audio_dir, class_to_idx, transform=None):\n",
    "        self.metadata = pd.read_csv(metadata_csv)\n",
    "        self.metadata.columns = self.metadata.columns.str.strip()\n",
    "        self.audio_dir = audio_dir\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        filename = row[\"Filename\"]\n",
    "        label = self.class_to_idx[row[\"Classname\"]]\n",
    "        file_path = os.path.join(self.audio_dir, filename)\n",
    "        \n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "        # If stereo, take the first channel.\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform[0:1, :]\n",
    "        # Resample if needed.\n",
    "        if sr != SAMPLE_RATE:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "            waveform = resampler(waveform)\n",
    "        # Squeeze to make waveform 1D.\n",
    "        waveform = waveform.squeeze(0)\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "train_dataset = AudioDataset(TRAIN_METADATA_CSV, TRAIN_AUDIO_DIR, class_to_idx, transform=None)\n",
    "test_dataset = AudioDataset(TEST_METADATA_CSV, TEST_AUDIO_DIR, class_to_idx, transform=None)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 6. Custom Collate Function for Raw Waveforms\n",
    "# ------------------------------------------------\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads raw 1D waveforms in the batch along the time dimension so that all waveforms have the same length.\n",
    "    \"\"\"\n",
    "    waveforms, labels = zip(*batch)\n",
    "    max_length = max(waveform.shape[0] for waveform in waveforms)\n",
    "    padded_waveforms = []\n",
    "    for waveform in waveforms:\n",
    "        pad_length = max_length - waveform.shape[0]\n",
    "        padded_waveform = F.pad(waveform, (0, pad_length))\n",
    "        padded_waveforms.append(padded_waveform)\n",
    "    stacked_waveforms = torch.stack(padded_waveforms, dim=0)  # [batch_size, max_length]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return stacked_waveforms, labels\n",
    "\n",
    "train_loader_full = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 7. Define Model Parameters and Initialize Model\n",
    "# ------------------------------------------------\n",
    "# Here we specify our model parameters. Note that the pretrained CNN14 checkpoint was trained on AudioSet (527 classes).\n",
    "# Since your dataset has only 7 classes, we will initialize a new final layer.\n",
    "model_params = {\n",
    "    \"sample_rate\": SAMPLE_RATE,\n",
    "    \"window_size\": N_FFT,\n",
    "    \"hop_size\": HOP_LENGTH,\n",
    "    \"mel_bins\": N_MELS,\n",
    "    \"fmin\": FMIN,\n",
    "    \"fmax\": FMAX,\n",
    "    \"classes_num\": num_classes  # e.g., 7\n",
    "}\n",
    "\n",
    "# Initialize the model using the Wavegram_Logmel_Cnn14 variant.\n",
    "\n",
    "model = Cnn14(**model_params)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 8. Load Pretrained Weights (Filtering Out Final Classification Layer)\n",
    "# ------------------------------------------------\n",
    "# Load the pretrained checkpoint.\n",
    "checkpoint = torch.load(PRETRAINED_MODEL_PATH, map_location=DEVICE)\n",
    "pretrained_dict = checkpoint[\"model\"]\n",
    "\n",
    "# Remove keys corresponding to the final classification layer (often named \"fc_audioset\").\n",
    "filtered_dict = {k: v for k, v in pretrained_dict.items() if not k.startswith(\"fc_audioset\")}\n",
    "\n",
    "# Update the current model's state dict with the filtered pretrained weights.\n",
    "model_dict = model.state_dict()\n",
    "model_dict.update(filtered_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "print(\"Loaded pretrained weights (excluding final layer) successfully.\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 9. Loss and Optimizer\n",
    "# ------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 10. 3-Fold Cross-Validation on Training Set\n",
    "# ------------------------------------------------\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "fold_f1 = []\n",
    "fold_precision = []\n",
    "fold_recall = []\n",
    "\n",
    "print(\"\\nStarting 3-Fold Cross-Validation...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"\\n--- Fold {fold+1} ---\")\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    # Initialize a new model for this fold and load the pretrained weights (excluding final layer).\n",
    "    model_fold = Cnn14(**model_params)\n",
    "    model_fold.to(DEVICE)\n",
    "    model_fold.load_state_dict(model_dict)\n",
    "    optimizer_fold = optim.Adam(model_fold.parameters(), lr=LEARNING_RATE)\n",
    "    criterion_fold = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model_fold.train()\n",
    "        running_loss = 0.0\n",
    "        for waveforms, labels in tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}\"):\n",
    "            waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer_fold.zero_grad()\n",
    "            outputs = model_fold(waveforms)\n",
    "            logits = outputs[\"clipwise_output\"]\n",
    "            loss = criterion_fold(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer_fold.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Fold {fold+1} Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    model_fold.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels in val_loader:\n",
    "            waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model_fold(waveforms)\n",
    "            logits = outputs[\"clipwise_output\"]\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    fold_f1.append(f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0))\n",
    "    fold_precision.append(precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0))\n",
    "    fold_recall.append(recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0))\n",
    "    print(f\"Fold {fold+1} - F1: {fold_f1[-1]:.4f}, Precision: {fold_precision[-1]:.4f}, Recall: {fold_recall[-1]:.4f}\")\n",
    "\n",
    "print(\"\\n--- Average 3-Fold Cross-Validation Results ---\")\n",
    "print(f\"F1 Score: {np.mean(fold_f1):.4f}\")\n",
    "print(f\"Precision: {np.mean(fold_precision):.4f}\")\n",
    "print(f\"Recall: {np.mean(fold_recall):.4f}\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 11. Train Final Model on Full Training Set and Evaluate on Test Set\n",
    "# ------------------------------------------------\n",
    "model_final = Cnn14(**model_params)\n",
    "model_final.to(DEVICE)\n",
    "model_final.load_state_dict(model_dict)  # Load pretrained weights excluding final layer.\n",
    "optimizer_final = optim.Adam(model_final.parameters(), lr=LEARNING_RATE)\n",
    "criterion_final = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\nTraining final model on full training set...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model_final.train()\n",
    "    total_loss = 0.0\n",
    "    for waveforms, labels in tqdm(train_loader_full, desc=f\"Final Model Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer_final.zero_grad()\n",
    "        outputs = model_final(waveforms)\n",
    "        logits = outputs[\"clipwise_output\"]\n",
    "        loss = criterion_final(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer_final.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Training Loss: {total_loss/len(train_loader_full):.4f}\")\n",
    "\n",
    "torch.save(model_final.state_dict(), \"trained_model_final.pth\")\n",
    "print(\"Final training complete. Model saved as 'trained_model_final.pth'.\")\n",
    "\n",
    "model_final.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for waveforms, labels in test_loader:\n",
    "        waveforms, labels = waveforms.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model_final(waveforms)\n",
    "        logits = outputs[\"clipwise_output\"]\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "\n",
    "1. **Configuration and Paths:**  \n",
    "   The notebook sets up all paths (dataset, metadata, pretrained model) according to the folder structure.\n",
    "\n",
    "2. **Data Preparation:**  \n",
    "   - The CSV metadata is loaded, and a class mapping is created based on the `\"Classname\"` column.\n",
    "   - A custom PyTorch `Dataset` (`AudioDataset`) loads raw audio waveforms (resampled to 32 kHz) from the specified folder.\n",
    "   - A custom collate function pads the variable-length waveforms so that they can be batched together.\n",
    "\n",
    "3. **Model Initialization:**  \n",
    "   - The pretrained CNN14 model is imported from the PANNs repository.\n",
    "   - The pretrained weights (from `Cnn14_mAP=0.431.pth`) are loaded, filtering out the final classification layer so that the output layer is reinitialized for our 7 classes.\n",
    "\n",
    "4. **Training and Evaluation:**  \n",
    "   - The notebook performs **3-fold cross-validation** on the training set, printing weighted F1 score, precision, and recall for each fold and their averages.\n",
    "   - A final model is then trained on the full training set and evaluated on the test set.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
